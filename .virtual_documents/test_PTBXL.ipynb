import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"


def find_diagnose(filename):

    with open(filename, "r") as file:
        lines = file.readlines()

    for line in lines:
        tofind = "# Reason for admission: "
        start = len(tofind)
        if tofind in line:
            diagnose = line[start:].strip()
    if diagnose == "n/a":
        return None
    else: #some signals in the dataset don't have a diagnose
        return diagnose


import wfdb


def multichannel_resample(signal, new_lenght):
    nchs = 15
    resampled_signal = np.zeros((new_lenght, nchs))
    for ch in range(nchs):
        resampled_signal[:, ch] = resample(signal[:, ch], new_lenght)
        #print(resampled_signal[:, ch].shape, resample(signal[:, ch], new_fs).shape)
    return resampled_signal


from scipy.signal import butter, lfilter, iirnotch

def bandpass(lowcut, highcut, order=3, fs = 500):
    
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a

def notch_filter(cutoff, q, fs=500):
    
    nyq = 0.5*fs
    freq = cutoff/nyq
    b, a = iirnotch(freq, q)
    return b, a

def myfilter(lowcut, highcut, powerline, data):
    
    nchs = 12
    filtered_data = np.zeros_like(data)
    for ch in range(nchs):
        ch_data = data[:, ch]
        b, a = bandpass(lowcut, highcut)   
        x = lfilter(b, a, ch_data)
        f, e = notch_filter(powerline, 30)
        z = lfilter(f, e, x) 
        filtered_data[:, ch] = (x)
    return filtered_data


import pandas as pd

cwd = os.getcwd() + os.sep
path = r"C:\\Users\\Utente\\Desktop\\Uni\\ECG_SR\\data\\1d\\PTBXL\\"
filename = path + "ptbxl_database.csv"
df = pd.read_csv(filename, sep=",", index_col="ecg_id")
df.head()


files =  list(df["filename_hr"].values)


noisy_files = []
n = len(files)
for i in range(n):

    print(i , end=" \r")
    row = df.iloc[i, :]
    filenamehr = row["filename_hr"]
    baselinedrift = row["baseline_drift"]
    staticnoise = row["static_noise"]
    electrodesproblems = row["electrodes_problems"]
    burstnoise = row["burst_noise"]
    if isinstance(baselinedrift, str) or isinstance(staticnoise, str)  or isinstance(electrodesproblems, str)  or isinstance(burstnoise, str):
        #print(baselinedrift, type(baselinedrift), staticnoise, type(staticnoise))
        noisy_files.append(filenamehr)
len(noisy_files)


import numpy as np 

files_no_noise = np.setdiff1d(files, noisy_files)
files_no_noise


newdf = df.copy()
for file in noisy_files:
    newdf = newdf[newdf["filename_hr"] != file]
newdf.head(10)


seconds = 10
nchs = 15
fs_hr = 500
lenght_hr = fs_hr*seconds


def load_raw_data(df, path):
    data = [] 
    n = len(df.filename_hr)
    for i, f in enumerate(df.filename_hr):
        print(i+1, "/", n, end=" \r")
        data.append(wfdb.rdsamp(path+f))
    data = np.array([signal.T for signal, meta in data])
    return data


cleanrecords_hr = newdf["filename_hr"]
data_hr = load_raw_data(newdf, path)


import torch 

n = len(data_hr)#or hr
nchs = 12
data_hr_tensor = torch.zeros((n, nchs, lenght_hr))
for i in range(n):
    print(i+1, "/", n, end=" \r")
    for j in range(nchs):
        temp_data_hr = torch.from_numpy(data_hr[i, j, :])
        data_hr_tensor[i, j, :] = temp_data_hr


import ast 

# load and convert annotation data
Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')
Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))

X_hr = load_raw_data(Y, path)

# Load scp_statements.csv for diagnostic aggregation
agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)
agg_df_diagnostic = agg_df[agg_df.diagnostic == 1]
agg_df_notdiagnostic = agg_df[agg_df.diagnostic != 1]

def aggregate_diagnostic(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df_diagnostic.index:
            tmp.append(agg_df_diagnostic.loc[key].diagnostic_class)
            break
    return list(set(tmp))

def aggregate_subclass(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df_diagnostic.index:
            tmp.append(agg_df_diagnostic.loc[key].diagnostic_subclass)
            break
    return list(set(tmp))

def aggregate_nondiagnostic(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df_notdiagnostic.index:
            tmp.append(key)
            break
    return list(set(tmp))

# Apply diagnostic superclass
Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)
Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_subclass)
Y['nondiagnostic_class'] = Y.scp_codes.apply(aggregate_nondiagnostic)


uqs, cnts = np.unique(Y['diagnostic_superclass'], return_counts = True)
for i, uq in enumerate(uqs):
    cnt = cnts[i]
    print(uq, ": ", cnt)


list(Y['diagnostic_superclass'].values)[0]


X_test = data_hr_tensor
y_test = list(Y['diagnostic_superclass'].values)
y_test_bin = [0 if y == ["NORM"] else 1 for y in y_test]
y_test_bin = torch.from_numpy(np.array(y_test_bin))
torch.unique(y_test_bin, return_counts = True)


def sliding_window(signal, size=500, stride=500):
    
    windows = []
    #print(signal.shape)
    sig_len = signal.shape[-1]
    win_num = math.ceil((sig_len - size) / stride) + 1
    for i in range(win_num):
        offset = i * stride
        #print(offset, offset + size)
        windows.append((signal[:, offset : offset + size]))
    return windows


def split_windows(data, width = 1500, stride = 1000):
    
    nchs = 15
    windows_data = []
    for i, signal in enumerate(data):
        windows = sliding_window(signal, width, stride = stride)
        for window in windows:
            windows_data.append(window)    
            
    temp = torch.zeros(len(windows_data), 1, nchs, width)
    
    for i, data in enumerate(windows_data):
        temp[i, :, :12, :] = torch.unsqueeze(data[:12], dim = 0)

    windows_data = temp
    return windows_data



#PTB-XL
#I, II, III, AVL, AVR, AVF, V1, ..., V6
#PTB
#(i, ii, iii, avr, avl, avf, v1, v2, v3, v4, v5, v6) 
#switch 3 - 4 


def arrange_leads(data):
    col1, col2 = 4, 3

    # Swap columns
    data[:, [col1, col2]] = data[:, [col2, col1]]
    return data





import math 
windows_test_hr = []
windows_labels = []

device = "cuda" if torch.cuda.is_available() else "cpu"

map_windows = {}
map_labels = {}

j = 0
for i, tensor in enumerate(X_test):

    print(i+1, "/", X_test.shape[0], end=" \r")
    label = y_test_bin[i]

    fs = 500
    width = fs*4
    stride = fs*3
    #print(tensor.shape, width, stride)
    tensor = tensor.unsqueeze(dim = 0)
    windows_data = split_windows(tensor, width = width, stride = stride)
    
    map_windows[i] = []
    map_labels[i] = label
    
    for window in windows_data:
        window = arrange_leads(window)
        windows_test_hr.append(window.to(device)) 
        windows_labels.append(label)
        map_windows[i].append(j)
        j += 1


map_windows


windows_test_hr = torch.stack(windows_test_hr)
windows_labels = torch.tensor(windows_labels)
windows_test_hr.shape, windows_labels.shape


idx_normal = np.argwhere(windows_labels == 0)
idx_ab = np.argwhere(windows_labels == 1)
x_normal = windows_test_hr[idx_normal].flatten()
y_normal = windows_labels[idx_normal].flatten()
x_ab = windows_test_hr[idx_ab].flatten()
y_ab =  windows_labels[idx_ab].flatten()


x_normal.shape, y_normal.shape, x_ab.shape, y_ab.shape


x_normal[0].shape


import matplotlib.pyplot as plt 
#plt.plot(x_normal_f[:10000].cpu(), label = "filtered")
plt.plot(x_normal[:10000].cpu(), label = "not filtered")
plt.legend()


#plt.plot(x_ab_f[:10000].cpu(), label = "filtered")
plt.plot(x_ab[:10000].cpu(), label = "not filtered")
plt.legend()


from sklearn.metrics import roc_curve, auc 

def plot_roc_curve(y, y_pred):
    # calculate the fpr, tpr, AUC and plot the ROC curve 
    '''
    input: 
    y: array-like contenente i valori dell'attributo target
    y_pred: array-like contenente le predizioni dell'attributo target
    output: None
    
    '''
    y = np.array(y)       #cast array-like in numpy array
    y_pred = np.array(y_pred)
    labels = np.unique(y)
    fpr, tpr, threshold = roc_curve(y, y_pred)
    #print(fpr, tpr)
    roc_auc = round(auc(fpr, tpr), 4)
    
    plt.title('ROC curve')
    plt.plot(fpr, tpr, 'b', label = 'AUC {}'.format(roc_auc))
    plt.legend(loc = 'lower right')
    plt.plot(labels, labels,'r--')
    plt.xlim([-0.05, 1])
    plt.ylim([0, 1.05])
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.show()


def plot_cm(cm):
    
    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd
    import numpy as np

    sns.set(style='white')
    fig, ax = plt.subplots(figsize=(12, 8))
    sns.heatmap(np.eye(2), annot=cm, fmt='g', annot_kws={'size': 50},
                cmap=sns.color_palette(['tomato', 'palegreen'], as_cmap=True), cbar=False,
                yticklabels=['Normal', 'Abnormal'], xticklabels=['Normal', 'Abnormal'], ax=ax)
    ax.xaxis.tick_top()
    ax.xaxis.set_label_position('top')
    ax.tick_params(labelsize=20, length=0)

    ax.set_title('Seaborn Confusion Matrix with labels', size=24, pad=20)
    ax.set_xlabel('Predicted Values', size=20)
    ax.set_ylabel('Actual Values', size=20)

    additional_texts = ['(True Positive)', '(False Negative)', '(False Positive)', '(True Negative)']
    for text_elt, additional_text in zip(ax.texts, additional_texts):
        ax.text(*text_elt.get_position(), '\n' + additional_text, color=text_elt.get_color(),
                ha='center', va='top', size=24)
    plt.tight_layout()
    plt.show()


from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report

def validate_model(y_trues, y_preds):

    TP = 0
    FP = 0
    TN = 0
    FN = 0
    idxs_missclassified = []

    for i, y_true in enumerate(y_trues):

        y_pred = y_preds[i]

        if y_true == 1: #"N":
            if y_pred == y_true:
                TN += 1
            else:
                FP += 1
                idxs_missclassified.append(i)

        else:
            if y_pred == y_true:
                TP += 1 
            else:
                FN += 1
            idxs_missclassified.append(i)
    
    TP, FN, FP, TN = confusion_matrix(y_trues, y_preds).ravel() 
            
    acc = (TP+TN)/(TP+TN+FP+FN)
    if FN + TP != 0:
        TPR = TP/(FN+TP) #sensitivity 
        FNR = FN/(FN+TP)
        recall = TPR
    else: 
        TPR = None
        FNR = None 
        recall = None
    
    if TN+FP != 0:
        
        TNR = TN/(TN+FP) #specificity
        FPR = FP/(TN+FP)
    else: 
        TNR = None
        FPR = None 
    
    if TP+FP != 0:
        precision = TP/(TP+FP)
    else:
        precision = None
    
    if precision != 0 and recall != 0:
        f1 = (2*precision*recall)/(precision+recall)
    else:
        f1 = None 
    
    cr = classification_report(y_trues, y_preds)
    cm = confusion_matrix(y_trues, y_preds)
    auc = roc_auc_score(y_trues, y_preds)
    metrics = {
        "accuracy": acc,
        "f1": f1,
        "cm": cm,
        "sensitivity": TPR,
        "specificity": TNR,
        "missed allarm rate": FPR,
        "false allarm rate": FNR,
        "auc_score": auc,
        "precision": precision,
        "recall": recall,
        "report": cr,
        "predictions": y_preds,
        "idxs_missclassified": idxs_missclassified
    }
    plot_roc_curve(y_trues, y_preds)
    plot_cm(cm)
    return metrics, "Accuracy: {} \n F1 score: {} \n Sensitivity: {} \n Specificity: {} \n ROC AUC score: {} \n False Allarm Rate: {}, Missed Allarm Rate: {} \n Confusion Matrix: \n {} \n Classification Report: \n {} \n".format(acc, f1, TPR, TNR, auc, FNR, FPR, cm, cr)


from IPython.display import clear_output


#!pip install dill


from EcgStuffs.src.dpnet import dpnet_loader, conf

if torch.cuda.is_available():
    model = dpnet_loader.load() #load auto encoder model
else:
    model =  dpnet_loader.load_cpu()
model.load_state_dict(torch.load("model.pt"))
model = model.to(device)


model.eval()


windows_test_hr.shape


data = windows_test_hr[0]
data = torch.unsqueeze(data, dim = 0).to(device)
reconstruction = model(data)


from torch.functional import F 

fs = 500 
nchs = 15 
interval2 = fs*3
interval = fs*4
reconstruction_errors = []
n = windows_test_hr.shape[0]

for i, batch_data in enumerate(windows_test_hr): 
    
    batch_data = batch_data.to(device)
    #print(batch_data.shape)
    batch_data = torch.unsqueeze(batch_data, dim = 0).to(device)

    #print(batch_data.shape)
    reconstruction_all = np.zeros((nchs, interval2))        

    with torch.no_grad():

        reconstruction = model(batch_data)
        reconstruction_error = F.mse_loss(reconstruction[0, 0, :, :interval2], batch_data[0, 0, :, :interval2]).item()
        if i+1 in np.arange(1, n, 5000):
            print(i+1, "/", n, "Recon error:", round(reconstruction_error, 6), end = "\r")
        reconstruction_errors.append(reconstruction_error)
        recon_np = (reconstruction[0, 0, :, :interval2].cpu().detach().numpy()).reshape(1, nchs, interval2)
        reconstruction_all[:, :] = recon_np[0, :, :interval2]

        torch.cuda.empty_cache()


len(reconstruction_errors)


from time import sleep
best_th = 0.0
best_auc = 0.0
normal_mse = []
anomalous_mse = []
count_decr = 0 
fprs = [0]
tprs = [0]
thresholds = np.arange(0.01, 0.5, 0.005)
for j, threshold in enumerate(thresholds):
    print(threshold)
    y_preds = []
    for i, recon_error in enumerate(reconstruction_errors):

        if j == 0:
            if windows_labels[i] == 0:
                normal_mse.append(recon_error)
            else:
                anomalous_mse.append(recon_error)

        if recon_error > threshold:
            y_preds.append(1)
        else:
            y_preds.append(0)
                
        y = windows_labels[i]
        
    sleep(0.5)
    clear_output(wait = True)
    metrics, to_print = validate_model(windows_labels, y_preds)
    auc_score = metrics["auc_score"]
    if auc_score > best_auc:
        best_th = threshold
        best_auc = auc_score
    if auc_score < best_auc:
        count_decr += 1
    if count_decr >= 10: 
        break
    fpr, tpr, _ = roc_curve(windows_labels, y_preds)
    fprs.append(fpr[1])
    tprs.append(tpr[1])
    print(to_print)
fprs.append(1)
tprs.append(1)


best_th, best_auc


#best_th = 0.026

windows_labels_preds = []
for i, recon_error in enumerate(reconstruction_errors):
    
    if recon_error > best_th:
        windows_labels_preds.append(1)
    else:
        windows_labels_preds.append(0)
                
    y = windows_labels[i]
        
metrics, to_print = validate_model(windows_labels, windows_labels_preds)
auc_score = metrics["auc_score"]
print(to_print)


roc_auc = round(auc(sorted(fprs), sorted(tprs)), 4)
plt.title('ROC curve')
plt.plot(sorted(fprs), sorted(tprs), 'b', label = 'AUC {}'.format(roc_auc))
plt.legend(loc = 'lower right')
plt.plot(labels, labels,'r--')
plt.xlim([-0.05, 1])
plt.ylim([0, 1.05])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()





channels = ["i", "ii", "iii", "aVR", "aVL", "aVF", "v1", "v2" ,"v3", "v4", "v5", "v6", "x", "y", "z"]


from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve

prec, recall, _ = precision_recall_curve(windows_labels,  windows_labels_preds)
auc_pr = auc(recall, prec)
pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot(label="auc-prc {}".format(round(auc_pr, 4)))
plt.plot([0, 1], [1, 0], "--r")
plt.xlim([0, 1])
plt.ylim([0, 1.1])
plt.legend()


def isSignalAnomalous(patient, windows, threshold, test, n_anomalies_th = 1, device = "cuda", verbose = True, model = model):

    reconstruction_errors = []
    reconstruction_windows = torch.zeros_like((windows))
    interval = 1500
    interval2 = 2000
        
    nchs = 15
    n_record = windows.shape[0]*interval
    reconstruction_all = np.zeros((nchs, n_record))
    
    for i, window in enumerate(windows):
        batch_data = torch.unsqueeze(window, dim = 0)
        batch_data = torch.unsqueeze(window, dim = 0)
        batch_data = batch_data.to(device)
        
        if i == 0:
            start = 0
            end = interval
        else:
            start += int(interval)
            end += int(interval) 
        
        #print(i, start, end)
        with torch.no_grad():
            reconstruction = model(batch_data)
            reconstruction_errors.append((F.mse_loss(reconstruction[0, 0, :, :interval], batch_data[0, 0, :, :interval])).item())
            reconstruction_windows[i, :, :] = reconstruction
            torch.cuda.empty_cache()
            if end > n_record:
                reconstruction_all[:, start:n_record] = recon_np[0, :, :interval2-(end-n_record)] #TO FIX START AND END
            else:
                reconstruction_all[:, start:end] = recon_np[0, :, :interval]
                
    predictions = []
    for recon_error in reconstruction_errors:
        if recon_error >= threshold:
            predictions.append(1)
        else:
            predictions.append(0)
            
    uqs, cnts = np.unique(predictions, return_counts = True)
    pred_cnts = {}

    for i, uq in enumerate(uqs):
        cnt = cnts[i]
        pred_cnts[uq] = cnt
    
    pred = 0# Normal
    if 1 in pred_cnts.keys():
        if pred_cnts[1] >= n_anomalies_th:
            pred = 1
    if verbose:
        print("Patient:", patient, "Target:", test,  "Prediction: ", pred, "Windows label:", uqs, "Windows counts:", cnts)
    
    reconstruction_all = torch.from_numpy(reconstruction_all).to(device)
    return reconstruction_all, pred, np.mean(recon_error), predictions


map_y_final = {0: "Normal", 1: "Anomalous"}


import matplotlib.patches as patches 

patient = list(map_windows.keys())[100]
windows = map_windows[patient]
#windows = torch.unsqueeze(windows, dim=1)
label = map_labels[patient].item()
recon, pred, mean_rec_error, predictions = isSignalAnomalous(patient, windows, best_th, label, n_anomalies_th = 1, device = "cuda", verbose = True)

nchs = 12#15
f, axs = plt.subplots(nchs, 1, sharex=True, figsize= (40, 40))

width = len(windows) * 2000
signal = torch.zeros(nchs, width)
start = 0
end = 2000
for window in windows:
    signal[:, start:end] = window[0, :nchs, :]
    start += 2000
    end += 2000
    
for ch in range(nchs):
    y_recon = recon[ch, limit0:limit1].cpu().detach().numpy()
    pred_windows = predictions[:n_windows]
    y = signal[ch, :]
    x = np.arange(0, y.shape[-1], 1)
    axs[ch].plot(x, y)
    axs[ch].set_title(channels[ch], fontweight='bold', fontsize = 26)
    
    
    end = 2000
    i = 0
    for start in range(0, width, 2000):
        prediction = predictions[i]
        if prediction == 1:
            #print(start, end)
            rect = patches.Rectangle((start, min(y)), 2000, abs(min(y)) + max(y), linewidth=1, edgecolor='r', facecolor='none')
            axs[ch].add_patch(rect)
        end += start
        i += 1
#plt.savefig("anomalies_identified.png", dpi = 300)


import matplotlib.patches as patches 

patient = list(map_windows.keys())[1000]
windows = map_windows[patient]
#windows = torch.unsqueeze(windows, dim=1)
label = map_labels[patient].item()
recon, pred, mean_rec_error, predictions = isSignalAnomalous(patient, windows, best_th, label, n_anomalies_th = 1, device = "cuda", verbose = True)

nchs = 12#15
f, axs = plt.subplots(nchs, 1, sharex=True, figsize= (40, 40))

width = len(windows) * 2000
signal = torch.zeros(nchs, width)
start = 0
end = 2000
for window in windows:
    signal[:, start:end] = window[0, :nchs, :]
    start += 2000
    end += 2000
    
for ch in range(nchs):
    y_recon = recon[ch, :].cpu().detach().numpy()
    pred_windows = predictions[:n_windows]
    y = signal[ch, :]
    x = np.arange(0, y.shape[-1], 1)
    axs[ch].plot(x, y)
    axs[ch].set_title(channels[ch], fontweight='bold', fontsize = 26)
    
    
    end = 2000
    i = 0
    for start in range(0, width, 2000):
        prediction = predictions[i]
        if prediction == 1:
            #print(start, end)
            rect = patches.Rectangle((start, min(y)), 2000, abs(min(y)) + max(y), linewidth=1, edgecolor='r', facecolor='none')
            axs[ch].add_patch(rect)
        end += start
        i += 1


def make_signal(windows):
    
    nchs = 12#15
    width = len(windows) * 2000
    signal = torch.zeros(nchs, width)
    start = 0
    end = 2000
    for window in windows:
        signal[:, start:end] = window[0, :nchs, :]
        start += 2000
        end += 2000
    return signal


channels = ["i", "ii", "iii", "aVR", "aVL", "aVF", "v1", "v2" ,"v3", "v4", "v5", "v6", "x", "y", "z"]


map_y_final = {0: "Normal", 1: "Anomalous"}


patient = 5000
windows = map_windows[patient]
y = map_labels[patient].item()
window = windows[0].to(device)
window = window.unsqueeze(dim=0)
recon = model(window)
reconstruction_error = F.mse_loss(window, recon).item()

ch = 0
plt.plot(window[0, 0, ch, :1500].cpu().detach().numpy(), label = "channel {}".format(channels[ch]))
plt.plot(recon[0, 0, ch, :1500].cpu().detach().numpy(), "--r", label = "reconstruction")
plt.title("Patient: {}, Reconstruction error: {}, Target: {}".format(patient, round(reconstruction_error , 4), map_y_final[y]))
plt.legend()


def isSignalAnomalous(patient, windows, threshold, test, n_anomalies_th = 1, device = "cuda", verbose = True, model = model):

    reconstruction_errors = []
    reconstruction_windows = torch.zeros_like((windows))
    interval = 1500
    interval2 = 2000
        
    nchs = 15
    n_record = windows.shape[0]*interval
    reconstruction_all = np.zeros((nchs, n_record))
    
    for i, window in enumerate(windows):
        batch_data = torch.unsqueeze(window, dim = 0)
        batch_data = torch.unsqueeze(window, dim = 0)
        batch_data = batch_data.to(device)
        
        if i == 0:
            start = 0
            end = interval
        else:
            start += int(interval)
            end += int(interval) 
        
        #print(i, start, end)
        with torch.no_grad():
            reconstruction = model(batch_data)
            reconstruction_errors.append((F.mse_loss(reconstruction[0, 0, :, :interval], batch_data[0, 0, :, :interval])).item())
            reconstruction_windows[i, :, :] = reconstruction
            torch.cuda.empty_cache()
            if end > n_record:
                reconstruction_all[:, start:n_record] = recon_np[0, :, :interval2-(end-n_record)] #TO FIX START AND END
            else:
                reconstruction_all[:, start:end] = recon_np[0, :, :interval]
                
    predictions = []
    for recon_error in reconstruction_errors:
        if recon_error >= threshold:
            predictions.append(1)
        else:
            predictions.append(0)
            
    uqs, cnts = np.unique(predictions, return_counts = True)
    pred_cnts = {}

    for i, uq in enumerate(uqs):
        cnt = cnts[i]
        pred_cnts[uq] = cnt
    
    pred = 0# Normal
    if 1 in pred_cnts.keys():
        if pred_cnts[1] >= n_anomalies_th:
            pred = 1
    if verbose:
        print("Patient:", patient, "Target:", test,  "Prediction: ", pred, "Windows label:", uqs, "Windows counts:", cnts)
    
    reconstruction_all = torch.from_numpy(reconstruction_all).to(device)
    return reconstruction_all, pred, np.mean(recon_error), predictions


y_preds_patient = {}
patients_missclassified = []
patients_windows_missclassified = []
signals_all = {}
recons_all = {}
recon_error_patients = {}
normal_mse_patient = []
abnormal_mse_patient = []

for i, (patient_signal, ws) in enumerate(map_windows.items()):
    print(i+1, "/", len(map_windows.keys()), end="\r")
    
    windows = [window for i, window in enumerate(windows_test_hr) if i in ws] 
    windows = torch.stack(windows)
    test = map_labels[patient_signal]
    recons_signal, pred, recon_error, predictions = isSignalAnomalous(patient_signal, windows, best_th, test, n_anomalies_th = 1, verbose = False) 
    recons_all[patient_signal] = recons_signal
    recon_error_patients[patient_signal] = recon_error
    signals_all[patient_signal] = make_signal(windows)
    y_preds_patient[patient_signal] = pred
    #print(test, pred)
    if test != pred:
        #print("missclassified")
        patients_missclassified.append(patient_signal)
        patients_windows_missclassified.append(patient_signal)
    elif len(np.unique(predictions)) > 1: 
        #print("missclassified windows")
        patients_windows_missclassified.append(patient_signal)
    if test == 0:
        normal_mse_patient.append(recon_error)
    else:
        abnormal_mse_patient.append(recon_error)


import seaborn as sns 


fig, ax1 = plt.subplots()

ax1.set_xlabel('MSE reconstruction error')
ax1.set_ylabel('Normal count', color="green")
sns.histplot(normal_mse_patient, kde=True,
             bins=1, color = 'green', ax = ax1)
ax1.tick_params(axis='y', labelcolor="green")

ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis

ax2.set_ylabel('Abnormal count', color="red")  # we already handled the x-label with ax1
sns.histplot(abnormal_mse_patient, kde=True, 
             bins=50, color = 'red', ax = ax2)
ax2.tick_params(axis='y', labelcolor="red")

fig.tight_layout()  # otherwise the right y-label is slightly clipped
fig.legend(labels = ["Normal", "Normal", "Abnormal", "Abnormal"], loc = "upper center")


fig, ax1 = plt.subplots()

ax1.set_xlabel('MSE reconstruction error')
ax1.set_ylabel('Normal count', color="green")
sns.histplot(normal_mse, kde=True, 
             bins=100, color = 'green', ax = ax1)
ax1.tick_params(axis='y', labelcolor="green")

ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis

ax2.set_ylabel('Abnormal count', color="red")  # we already handled the x-label with ax1
sns.histplot(anomalous_mse, kde=True, 
             bins=100, color = 'red', ax = ax2)
ax2.tick_params(axis='y', labelcolor="red")

fig.tight_layout()  # otherwise the right y-label is slightly clipped
fig.legend(labels = ["Normal", "Normal", "Abnormal", "Abnormal"], loc = "upper center")


sns.histplot(normal_mse, kde=True, 
             bins=100, color = 'green')
plt.vlines(x = best_th, ymin = 0, ymax = 90, color = "red", linewidth = 2, linestyles = "dashed")
plt.ylim([0, 90])
plt.text(x = best_th + 0.0001, y = 40, s = "threshold = {}".format(round(best_th, 6)))


sns.histplot(anomalous_mse, kde=True, 
             bins=100, color = 'darkorange')
plt.vlines(x = best_th, ymin = 0, ymax = 4500, color = "red", linewidth = 2, linestyles = "dashed")
plt.ylim([0, 4500])
plt.text(x = best_th + 0.01, y = 4300, s = "threshold = {}".format(round(best_th, 6)))


y_test_f = []
y_preds_f = []

for patient, test in map_labels.items():

    pred = y_preds_patient[patient]
    y_test_f.append(test)
    y_preds_f.append(pred)


len(y_preds_f), len(y_test_f)


rocauc, to_print = validate_model(y_test_f, y_preds_f)
print(to_print)


from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve

prec, recall, _ = precision_recall_curve(y_test_f, y_preds_f)
auc_pr = auc(recall, prec)
pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot(label="auc-prc {}".format(round(auc_pr, 4)))
plt.plot([0, 1], [1, 0], "--r")
plt.xlim([0, 1])
plt.ylim([0, 1.1])
plt.legend()
